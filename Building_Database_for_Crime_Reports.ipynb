{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Database for Crime Reports\n",
    "\n",
    "In this project, we will build a database named *crimes_db* with a table named boston_crimes with appropriate datatypes for storing the data from the *boston.csv* file. We'll also create the table inside a schema named *crimes*, as well as create groups *readonly* and *readwrite*, each with the appropriate privileges. Lastly, we will create a user for each of these groups. \n",
    "\n",
    "Below is a diagram that illustrates a high level overview of our tasks:\n",
    "<img src=\"diagram_illustration.png\">\n",
    "\n",
    "## Creating the Crime Database\n",
    "\n",
    "We will start by creating a database for storing our crime data as well as a schema for containing the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2 # a PostgreSQL database adapter for the Python\n",
    "\n",
    "# Make a connection to the database\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "conn.autocommit = True #autocommit statementl\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP DATABASE IF EXISTS crime_db;\")\n",
    "cur.execute(\"CREATE DATABASE crime_db OWNER dq;\")\n",
    "cur.execute(\"DROP SCHEMA IF EXISTS crimes CASCADE;\")\n",
    "cur.execute(\"CREATE SCHEMA crimes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Column Names and Sample\n",
    "\n",
    "Then we gather data about our crime dataset so that we can more easily select the right datatypes to use in our table. Having access to the column headers and the first row of data will help us create the table. With access to column headers we do not have to remember the names of the columns, and with access to the first row of data, we can easily recall what kind of data is stored in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv # for parsing CSV files\n",
    "\n",
    "with open(\"boston.csv\") as file:\n",
    "    rows = list(csv.reader(file)) \n",
    "    col_headers = rows[0] # store the column headers\n",
    "    first_row = rows[1] # store the first row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298329"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows[1:]) # number of rows of data in CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Auxiliary Function\n",
    "\n",
    "We need to identify the proper datatypes for the columns. We'll create a function, *get_col_value_set()*, that given the name of a CSV file and a column index, we return the a set of distinct values contained in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_value_set(csv_filename, col_index):\n",
    "    with open(csv_filename) as file:\n",
    "        next(file)\n",
    "        rows = list(csv.reader(file))\n",
    "        values = set()\n",
    "        for row in rows:\n",
    "            values.add(row[col_index])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t298329\n",
      "offense_code\t219\n",
      "description\t239\n",
      "date\t1177\n",
      "day_of_the_week\t7\n",
      "lat\t18177\n",
      "long\t18177\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(col_headers)):\n",
    "    values = get_col_value_set(\"boston.csv\", index)\n",
    "    print(col_headers[index], len(values), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Maximum Length\n",
    "\n",
    "With the function, we were able to compute the number of distinct values for each column. Next, we want to know what is the longest word in any column containing textual data. There are two textual columns in the data set, *description* and *day_of_the_week*. We can tell that the day of the week that has the longest word is *Wednesday*. Next, we'll compute the maximum length of each value in the *description* column. However, we'll create a function to assist us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_max_length(csv_filename, col_index):\n",
    "    \"\"\"Returns the max character length from a given filename and index.\"\"\"\n",
    "    max_length = 0\n",
    "    col_values = get_col_value_set(csv_filename, col_index)  \n",
    "    for item in col_values:\n",
    "        max_length = max(max_length, len(item))\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t6\n",
      "offense_code\t4\n",
      "description\t58\n",
      "date\t10\n",
      "day_of_the_week\t9\n",
      "lat\t11\n",
      "long\t12\n"
     ]
    }
   ],
   "source": [
    "# Prints the max length for each column header of the file boston.csv\n",
    "for index in range(len(col_headers)):\n",
    "    max_len = get_max_length(\"boston.csv\", index)\n",
    "    print(col_headers[index], max_len, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Table\n",
    "\n",
    "We'll create the boston_crimes inside the crime schema of the crime_db database, using the information we have learned thus far to select the appropriate datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "print(col_headers)\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same names as the column headers for table columns. Because the column *day_of_the_week* has only 7 distinct values, it is suited to have an enumerated datatype. The *date* column will have a data type of DATE.\n",
    "\n",
    "The *incident_number* column has whole distinct numbers so we will use the type INT as well as make it the PRIMARY KEY for the table. \n",
    "\n",
    "The *offense_code* column will also have a data type of INT. Note: To save space, SMALLINT data type can be used as well based on the maximum length of the column of the file. \n",
    "\n",
    "We saw that the *description* column has values that are at most 58 characters long. To be on the safe side, we will limit the size of the description to 100 characters and use the VARCHAR(100) datatype.\n",
    "\n",
    "The *lat* and *long* columns has numbers that involves a lot of precision, so we will use the NUMERIC type. Note: DECIMAL data type can be used as well, they are both equivalent to each other.  \n",
    "\n",
    "Below is a chart summarizing what was discussed:\n",
    "\n",
    "| Columns           | Data Types       |\n",
    "|-------------------|------------------|\n",
    "| 'incident_number' | INT, PRIMARY KEY |\n",
    "| 'offense_code'    | INT              |\n",
    "| 'description'     | VARCHAR(100)     |\n",
    "| 'date'            | DATE             |\n",
    "| 'day_of_the_week' | ENUM (day_of_week)      |\n",
    "| 'lat'             | NUMERIC          |\n",
    "| 'long'            | NUMERIC          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the enumerated datatype for representing the weekday\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TYPE day_of_week AS ENUM ('Sunday', 'Monday', \n",
    "    'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday');\n",
    "\"\"\")\n",
    "\n",
    "# Create the table\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE crimes.boston_crimes (\n",
    "        incident_number INTEGER PRIMARY KEY,\n",
    "        offense_code INTEGER,\n",
    "        description VARCHAR(100),\n",
    "        date DATE,\n",
    "        day_of_the_week day_of_week,\n",
    "        lat NUMERIC,\n",
    "        long NUMERIC\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We'll load the data from the *boston.csv* file into the *crimes.boston_crimes* table using the [cursor.copy_expert()](http://initd.org/psycopg/docs/cursor.html#cursor.copy_expert) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298329,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"boston.csv\") as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM crimes.boston_crimes\")\n",
    "# print the number of rows to ensure that they were loaded\n",
    "print(cur.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revoking Public Privileges\n",
    "\n",
    "To recap, we have created a database with a schema inside it for holding data about crimes. We selected the right datatypes for storing the data, created a table and loaded the CSV containing crimes about Boston. \n",
    "\n",
    "Now, we'll create two user groups, *readonly* and *readwrite*. By following the least privilege principle, we'll make sure that there are no privileges inherited from the *public* group and on the *public* schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating User Groups\n",
    "\n",
    "Now, we'll create the two user groups. We will create them with NOLOGIN because it is a group and not a user. Then we will grant the group the ability to connect to the crime_db and the ability to use the crimes schema.\n",
    "\n",
    "The readonly group is supposed to only have privileges to perform SELECT queries, whereas we want the readwrite group to be able to perform SELECT, INSERT, DELETE and UPDATE queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute commands for readonly group\n",
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute commands for readwrite group\n",
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Users\n",
    "\n",
    "We'll create two users and assign each them to the appropriate group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Database Setup\n",
    "\n",
    "It is always good practice to test that everything is configured as expected after the database setup has been complete. \n",
    "\n",
    "We'll use SQL queries to check whether the objects have been created and that users and groups have the right privileges. We'll query the [*pg_roles*](https://www.postgresql.org/docs/10/view-pg-roles.html) table to inspect privileges related to the database and the [*information_schema.table_privileges*](https://www.postgresql.org/docs/9.1/infoschema-table-privileges.html) table to inspect table privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('readonly', False, False, False, False), ('readwrite', False, False, False, False), ('data_analyst', False, False, False, True), ('data_scientist', False, False, False, True)]\n"
     ]
    }
   ],
   "source": [
    "# check users and groups\n",
    "cur.execute(\"\"\"\n",
    "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb, rolcanlogin \n",
    "    FROM pg_roles\n",
    "    WHERE rolname IN ('readonly', 'readwrite', 'data_analyst', 'data_scientist');\n",
    "\"\"\")\n",
    "\n",
    "users = cur.fetchall()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('readonly', 'SELECT'), ('readwrite', 'INSERT'), ('readwrite', 'SELECT'), ('readwrite', 'UPDATE'), ('readwrite', 'DELETE')]\n"
     ]
    }
   ],
   "source": [
    "# check table privileges\n",
    "cur.execute(\"\"\"\n",
    "    SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee IN ('readonly', 'readwrite')\n",
    "\"\"\")\n",
    "\n",
    "privileges = cur.fetchall()\n",
    "print(privileges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
